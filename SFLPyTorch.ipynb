{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version :  2.2.2\n",
      "GPU :  0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('PyTorch Version : ', torch.__version__) \n",
    "print('GPU : ', torch.cuda.device_count())\n",
    "GPUNUM = torch.cuda.device_count()\n",
    "if GPUNUM == 0:\n",
    "    torch.cuda.is_available = lambda : False\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(2048, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if GPUNUM == 0:\n",
    "                data, target = data.cpu(), target.cpu()\n",
    "            else :\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def server_aggregate(global_model, client_models):\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k] for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "def test(global_model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if GPUNUM == 0:\n",
    "                data, target = data.cpu(), target.cpu()\n",
    "            else :\n",
    "                data, target = data.cuda(), target.cuda()            \n",
    "            # data, target = data.cuda(), target.cuda()\n",
    "            output = global_model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 0.549 | test loss 0.462 | test acc: 0.869\n",
      "1-th round\n",
      "average train loss 0.113 | test loss 0.262 | test acc: 0.924\n",
      "2-th round\n",
      "average train loss 0.0599 | test loss 0.191 | test acc: 0.945\n",
      "3-th round\n",
      "average train loss 0.0575 | test loss 0.161 | test acc: 0.955\n",
      "4-th round\n",
      "average train loss 0.043 | test loss 0.145 | test acc: 0.960\n"
     ]
    }
   ],
   "source": [
    "# IID case: all the clients have images of all the classes\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_clients = 100\n",
    "num_selected = 10\n",
    "num_rounds = 5\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Creating decentralized datasets\n",
    "\n",
    "traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                       )\n",
    "traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        ), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "\n",
    "if GPUNUM == 0:\n",
    "    global_model = Net().cpu()\n",
    "    client_models = [Net().cpu() for _ in range(num_selected)]\n",
    "else:\n",
    "    global_model = Net().cuda()\n",
    "    client_models = [Net().cuda() for _ in range(num_selected)]\n",
    "\n",
    "# global_model = Net().cuda()\n",
    "# client_models = [Net().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
    "\n",
    "# Runnining FL\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in range(num_selected):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\n",
    "    \n",
    "    # serer aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    \n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 0.0318 | test loss 2.8 | test acc: 0.275\n",
      "1-th round\n",
      "average train loss 0.0179 | test loss 1.94 | test acc: 0.409\n",
      "2-th round\n",
      "average train loss 0.00782 | test loss 1.83 | test acc: 0.428\n",
      "3-th round\n",
      "average train loss 0.0245 | test loss 2.09 | test acc: 0.400\n",
      "4-th round\n",
      "average train loss 0.00537 | test loss 4.73 | test acc: 0.215\n",
      "5-th round\n",
      "average train loss 0.00362 | test loss 3.4 | test acc: 0.189\n",
      "6-th round\n",
      "average train loss 0.00404 | test loss 3.32 | test acc: 0.321\n",
      "7-th round\n",
      "average train loss 0.0694 | test loss 1.36 | test acc: 0.520\n",
      "8-th round\n",
      "average train loss 0.0304 | test loss 1.54 | test acc: 0.528\n",
      "9-th round\n",
      "average train loss 0.0158 | test loss 1.14 | test acc: 0.700\n",
      "10-th round\n",
      "average train loss 0.00102 | test loss 1.05 | test acc: 0.644\n",
      "11-th round\n",
      "average train loss 0.00128 | test loss 1.52 | test acc: 0.510\n",
      "12-th round\n",
      "average train loss 0.00128 | test loss 2.16 | test acc: 0.378\n",
      "13-th round\n",
      "average train loss 0.000803 | test loss 1.95 | test acc: 0.467\n",
      "14-th round\n",
      "average train loss 0.00178 | test loss 0.974 | test acc: 0.647\n",
      "15-th round\n",
      "average train loss 0.0125 | test loss 0.694 | test acc: 0.750\n",
      "16-th round\n",
      "average train loss 0.000972 | test loss 0.825 | test acc: 0.747\n",
      "17-th round\n",
      "average train loss 0.00056 | test loss 0.906 | test acc: 0.673\n",
      "18-th round\n",
      "average train loss 0.00124 | test loss 0.742 | test acc: 0.738\n",
      "19-th round\n",
      "average train loss 0.000524 | test loss 1.33 | test acc: 0.586\n",
      "20-th round\n",
      "average train loss 0.000562 | test loss 0.779 | test acc: 0.713\n",
      "21-th round\n",
      "average train loss 0.00607 | test loss 0.629 | test acc: 0.751\n",
      "22-th round\n",
      "average train loss 0.000331 | test loss 1.05 | test acc: 0.675\n",
      "23-th round\n",
      "average train loss 0.0013 | test loss 0.545 | test acc: 0.815\n",
      "24-th round\n",
      "average train loss 0.000164 | test loss 0.444 | test acc: 0.823\n",
      "25-th round\n",
      "average train loss 0.00204 | test loss 0.298 | test acc: 0.912\n",
      "26-th round\n",
      "average train loss 0.000685 | test loss 0.315 | test acc: 0.905\n",
      "27-th round\n",
      "average train loss 0.00106 | test loss 0.526 | test acc: 0.804\n",
      "28-th round\n",
      "average train loss 0.000717 | test loss 0.437 | test acc: 0.856\n",
      "29-th round\n",
      "average train loss 0.00145 | test loss 1.63 | test acc: 0.578\n",
      "30-th round\n",
      "average train loss 0.00305 | test loss 1.92 | test acc: 0.512\n",
      "31-th round\n",
      "average train loss 0.000858 | test loss 0.898 | test acc: 0.701\n",
      "32-th round\n",
      "average train loss 0.000403 | test loss 0.794 | test acc: 0.749\n",
      "33-th round\n",
      "average train loss 0.000967 | test loss 0.631 | test acc: 0.780\n",
      "34-th round\n",
      "average train loss 0.000585 | test loss 0.522 | test acc: 0.804\n",
      "35-th round\n",
      "average train loss 0.00055 | test loss 0.472 | test acc: 0.827\n",
      "36-th round\n",
      "average train loss 0.000473 | test loss 0.61 | test acc: 0.777\n",
      "37-th round\n",
      "average train loss 0.000317 | test loss 0.689 | test acc: 0.771\n",
      "38-th round\n",
      "average train loss 0.000692 | test loss 0.615 | test acc: 0.805\n",
      "39-th round\n",
      "average train loss 0.00031 | test loss 0.71 | test acc: 0.773\n",
      "40-th round\n",
      "average train loss 0.000343 | test loss 0.575 | test acc: 0.796\n",
      "41-th round\n",
      "average train loss 0.000138 | test loss 0.311 | test acc: 0.886\n",
      "42-th round\n",
      "average train loss 0.000523 | test loss 0.283 | test acc: 0.910\n",
      "43-th round\n",
      "average train loss 0.00049 | test loss 0.306 | test acc: 0.900\n",
      "44-th round\n",
      "average train loss 0.00058 | test loss 0.226 | test acc: 0.930\n",
      "45-th round\n",
      "average train loss 0.00111 | test loss 0.233 | test acc: 0.922\n",
      "46-th round\n",
      "average train loss 0.000885 | test loss 0.226 | test acc: 0.927\n",
      "47-th round\n",
      "average train loss 0.000254 | test loss 0.447 | test acc: 0.842\n",
      "48-th round\n",
      "average train loss 0.000207 | test loss 0.358 | test acc: 0.871\n",
      "49-th round\n",
      "average train loss 0.00251 | test loss 0.255 | test acc: 0.910\n"
     ]
    }
   ],
   "source": [
    "# NON-IID case: every client has images of two categories chosen from [0, 1], [2, 3], [4, 5], [6, 7], or [8, 9].\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_clients = 100\n",
    "num_selected = 5\n",
    "num_rounds = 50\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Creating decentralized datasets\n",
    "\n",
    "traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                       )\n",
    "target_labels = torch.stack([traindata.targets == i for i in range(10)])\n",
    "target_labels_split = []\n",
    "for i in range(5):\n",
    "    target_labels_split += torch.split(torch.where(target_labels[(2 * i):(2 * (i + 1))].sum(0))[0], int(60000 / num_clients))\n",
    "traindata_split = [torch.utils.data.Subset(traindata, tl) for tl in target_labels_split]\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        ), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "if GPUNUM == 0:\n",
    "    global_model = Net().cpu()\n",
    "    client_models = [Net().cpu() for _ in range(num_selected)]\n",
    "else:\n",
    "    global_model = Net().cuda()\n",
    "    client_models = [Net().cuda() for _ in range(num_selected)]\n",
    "# global_model = Net().cuda()\n",
    "# client_models = [Net().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
    "\n",
    "# Runnining FL\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in range(num_selected):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\n",
    "    \n",
    "    # serer aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    \n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
